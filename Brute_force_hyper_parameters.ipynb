{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Brute force hyper-parameters.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timwinter06/internship/blob/master/Brute_force_hyper_parameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEs_mjkzkt85",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "d3d37cb4-a0ea-4ca7-c32a-7df064ea7dce"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "import scipy.io as sio\n",
        "import os\n",
        "import random\n",
        "\n",
        "from itertools import product\n",
        "from collections import namedtuple\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OegTWnvfkt9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define functions\n",
        "\n",
        "def shuffle_in_unison(a, b):\n",
        "    rng_state = np.random.get_state()\n",
        "    np.random.shuffle(a)\n",
        "    np.random.set_state(rng_state)\n",
        "    np.random.shuffle(b)\n",
        "    return a, b\n",
        "\n",
        "def feature_normalize(dataset, label):\n",
        "    \n",
        "    mu = np.mean(dataset, axis=1)\n",
        "    sigma = np.std(dataset, axis=1)\n",
        "    \n",
        "    if np.any(sigma == 0):\n",
        "        print('There are sigmas = 0, these are removed.')\n",
        "        \n",
        "    # Find where sigmas are zero and remove those trials\n",
        "    ind = np.where(sigma == 0)\n",
        "    dataset = np.delete(dataset,ind,0)\n",
        "    label = np.delete(label,ind,0)\n",
        "    sigma = np.delete(sigma,ind,0)\n",
        "    mu = np.delete(mu,ind,0)\n",
        "    normal = np.transpose((np.transpose(dataset) - mu)/sigma)\n",
        "    \n",
        "    return normal, label, ind\n",
        "\n",
        "def import_data(animal, direct): # select animal (as string) to import data from\n",
        "    # Import all the data in the Processed data file\n",
        "    directory = direct + animal\n",
        "    fnames = os.listdir(directory)\n",
        "    whisk_data = {}\n",
        "    nr_files = len(fnames)\n",
        "    for i in range (0, nr_files):\n",
        "        fname = directory + '//' + fnames[i]\n",
        "        whisk_data[i] = sio.loadmat(fname)\n",
        "    return (whisk_data)\n",
        "\n",
        "def pre_process(whisk_data, no_zero, corr):\n",
        "    nr_files = len(whisk_data.keys())\n",
        "    shapes = np.zeros((2,nr_files))\n",
        "    for i in range (0,nr_files):\n",
        "        shapes[:,i] = whisk_data[i]['xtrain'].shape\n",
        "    # Pad the whisking traces to ensure they are all the same length\n",
        "    length = int(np.min(shapes[1,:]))\n",
        "    whisk = {}  \n",
        "    for i in range (0,nr_files):\n",
        "        whisk_2 = np.zeros((whisk_data[i]['xtrain'].shape[0], length))\n",
        "        whisk_2[:,0:int(length/2)] = whisk_data[i]['xtrain'][:,0:int(length/2)]\n",
        "        whisk_2[:,int(length/2)+1:] = whisk_data[i]['xtrain'][:,whisk_data[i]['xtrain'].shape[1]-int(length/2)+1:]\n",
        "        whisk[i] = whisk_2\n",
        "    \n",
        "    # Let's create one array with all of the training data \n",
        "    x_whisk = whisk[0]\n",
        "    y_whisk = whisk_data[0]['ytrain']\n",
        "\n",
        "    for i in range (1,nr_files):\n",
        "        x_whisk = np.concatenate((x_whisk , whisk[i]), axis =0)\n",
        "        y_whisk = np.concatenate((y_whisk , whisk_data[i]['ytrain']), axis =0)\n",
        "        \n",
        "    correct = whisk_data[0]['correct']\n",
        "    for i in range (1,nr_files):\n",
        "        correct = np.concatenate((correct,whisk_data[i]['correct']),axis = 0)\n",
        "            \n",
        "    if no_zero == 1:\n",
        "        # Delete rows of array with no pole location (pole location = 0)\n",
        "        zero = np.where(y_whisk[:,1] == 0)\n",
        "        x_whisk = np.delete(x_whisk,zero,0)\n",
        "        y_whisk = np.delete(y_whisk,zero,0)  \n",
        "        correct = np.delete(correct,zero,0)\n",
        "    if corr == 1:\n",
        "        # Only take correct data\n",
        "        ind = np.where(correct == 1)\n",
        "        x_whisk = x_whisk[ind[0],:]\n",
        "        y_whisk = y_whisk[ind[0],:]\n",
        "        \n",
        "    x_whisk, y_whisk = shuffle_in_unison(x_whisk, y_whisk)\n",
        "    # Split data into train and test data, roughly 80-20\n",
        "    split = round(0.8*x_whisk.shape[0])\n",
        "    xtrain = x_whisk[0:split,:]\n",
        "    xtest = x_whisk[split + 1:,:]\n",
        "    ytrain = y_whisk[0:split,0]\n",
        "    ytest = y_whisk[split + 1:,0]\n",
        "    xtrain = xtrain.astype(\"float32\")\n",
        "    ytrain = ytrain.astype(\"float32\")\n",
        "    xtest = xtest.astype(\"float32\")\n",
        "    ytest = ytest.astype(\"float32\")\n",
        "    length_2_trial = xtrain.shape[1]\n",
        "    length_trial = int(length_2_trial/2)\n",
        "    x_train_angle = xtrain[:, length_trial:length_2_trial ]\n",
        "    x_train_curve = xtrain[:, 0:length_trial ]\n",
        "    x_test_angle = xtest[:, length_trial:length_2_trial ]\n",
        "    x_test_curve = xtest[:, 0:length_trial ]\n",
        "    # And normalise the data\n",
        "    x_train_curve, ytrain, ind_1 = feature_normalize(x_train_curve, ytrain)\n",
        "    x_train_angle = np.delete(x_train_angle,ind_1[0],0)\n",
        "    x_train_angle, ytrain, ind_2 = feature_normalize(x_train_angle, ytrain)\n",
        "    x_train_curve = np.delete(x_train_curve,ind_2[0],0)\n",
        "    x_test_curve, ytest, ind_3 = feature_normalize(x_test_curve, ytest)\n",
        "    x_test_angle = np.delete(x_test_angle,ind_3[0],0)\n",
        "    x_test_angle, ytest, ind_4 = feature_normalize(x_test_angle, ytest)\n",
        "    x_test_curve = np.delete(x_test_curve,ind_4[0],0)\n",
        "    # concatenate all data\n",
        "    x_train_all = np.concatenate((x_train_curve, x_train_angle), axis = 1)\n",
        "    x_test_all = np.concatenate((x_test_curve, x_test_curve), axis = 1)\n",
        "    for i in range (0,ytrain.shape[0]):\n",
        "        if ytrain[i] == -1:\n",
        "            ytrain[i] = 0\n",
        "    for i in range (0,ytest.shape[0]):\n",
        "        if ytest[i] == -1:\n",
        "            ytest[i] = 0\n",
        "    num_classes = 2\n",
        "    ytrain = utils.to_categorical(ytrain, num_classes)\n",
        "    ytest = utils.to_categorical(ytest, num_classes)\n",
        "    return (x_train_all, x_test_all, ytrain, ytest, x_train_curve, x_train_angle, x_test_curve, x_test_angle)\n",
        "\n",
        "def plot_some(x_t_c, x_t_a, ytrain, number, save, name, rnd ):\n",
        "    # Lets plot random proximal trials and 10 random distal trials\n",
        "    prox = np.where(ytrain == [1, 0])\n",
        "    dist = np.where(ytrain == [0, 1])\n",
        "    width = 0.5\n",
        "    mark = 0.5\n",
        "    ymin = -20\n",
        "    ymax = 20\n",
        "\n",
        "    prox = np.ndarray.tolist(prox[0])\n",
        "    dist = np.ndarray.tolist(dist[0])\n",
        "\n",
        "    fig = plt.figure( figsize = (18,9))\n",
        "\n",
        "    ax1 = plt.subplot(221)\n",
        "    ax2 = plt.subplot(222)\n",
        "    ax3 = plt.subplot(223)\n",
        "    ax4 = plt.subplot(224)\n",
        "    \n",
        "    if rnd == 1:\n",
        "      rnd_p = random.sample(prox, number)\n",
        "      rnd_d = random.sample(dist, number)\n",
        "    elif rnd == 0:\n",
        "      rnd_p = prox\n",
        "      rnd_d = dist\n",
        " \n",
        "    x_train_curve = x_t_c\n",
        "    x_train_angle = x_t_a\n",
        "\n",
        "    for n in range (0, len(rnd_p)):\n",
        "        # Plot proximal\n",
        "        ax1.plot(x_train_curve[rnd_p[n],:],'b',linewidth = width, markersize = mark) # plot curve\n",
        "        ax1.set_title('Proximal curvature')\n",
        "        ax1.set_ylim([ymin,ymax])\n",
        "        ax1.set_xlabel('time/ms')\n",
        "        ax2.plot(x_train_angle[rnd_p[n],:],'b',linewidth = width,markersize = mark) # plot angle\n",
        "        ax2.set_title('Proximal angle')\n",
        "        ax2.set_ylim([ymin,ymax])\n",
        "        ax2.set_xlabel('time/ms')\n",
        "    for n in range (0, len(rnd_d)):\n",
        "        # Plot distal\n",
        "        ax3.plot(x_train_curve[rnd_d[n],:],'r',linewidth = width,markersize = mark) # plot curve\n",
        "        ax3.set_title('Distal curvature')\n",
        "        ax3.set_ylim([ymin,ymax])\n",
        "        ax3.set_xlabel('time/ms')\n",
        "        ax4.plot(x_train_angle[rnd_d[n],:],'r',linewidth = width,markersize = mark) # plot angle\n",
        "        ax4.set_title('Distal angle')\n",
        "        ax4.set_ylim([ymin,ymax])\n",
        "        ax4.set_xlabel('time/ms')\n",
        "    if save == 1:\n",
        "      fig.savefig(name)\n",
        "    return()\n",
        "\n",
        "def get_runs(params):\n",
        "  Run = namedtuple('Run', params.keys())\n",
        "  runs = []\n",
        "  for v in product(*params.values()):\n",
        "      runs.append(Run(*v))\n",
        "  return runs\n",
        "\n",
        "  # Make function that runs the test function a few times and then returns the average of the accuracy.\n",
        "\n",
        "# Pass functions, data, and the number of trainings you want to average over\n",
        "\n",
        "def find_average_metrics(find_hyper, find_hyper_LSTM, data, number, LongShort): # Set LSTM to 0 to train CNN, set it to 1 to train LSTM-CNN\n",
        "  \n",
        "  # Define dictionary to store performance in\n",
        "  history = {}\n",
        "  score = {}\n",
        "\n",
        "  # Make loop where each time the performance of the network is calculated\n",
        "  \n",
        "  for n in range (number):\n",
        "    print('Run of training: ' + str(n))\n",
        "\n",
        "    # Make network for all parameter combinations and train and test it\n",
        "    if LongShort == 0:\n",
        "      all_history, all_score, model = find_hyper(data['xtrain'], data['xtest'], data['ytrain'], data['ytest'], data['hyper'])\n",
        "    if LongShort == 1:\n",
        "      all_history, all_score, model = find_hyper_LSTM(data['x_train_curve'], data['x_train_angle'], data['x_test_curve'], data['x_test_angle'], data['ytrain'], data['ytest'], data['hyper'])\n",
        "    # Now save the taining and testing performance for this run\n",
        "\n",
        "    history[n] = all_history\n",
        "    score[n] = all_score\n",
        "\n",
        "  return(history, score)\n",
        "\n",
        "  # Calculate average of the trials\n",
        "def get_average (history, score):\n",
        "  metrics = {}\n",
        "  metrics['val_acc'] = np.zeros((len(history), len(history[0])))\n",
        "  metrics['test_acc'] = np.zeros((len(history), len(history[0])))\n",
        "  metrics['val_loss'] = np.zeros((len(history), len(history[0])))\n",
        "  metrics['test_loss'] = np.zeros((len(history), len(history[0])))\n",
        "\n",
        "  # Get the val and test acc for each combination for each run\n",
        "\n",
        "  for i in range (len(history)):\n",
        "    for t in range (len(history[0])):\n",
        "      metrics['val_acc'][ i, t] = history[i][t]['val_accuracy'][-1]    # Validation accuracy\n",
        "      metrics['test_acc'][ i, t] = score[i][t][1]                  # Test accuracy\n",
        "      metrics['test_loss'][ i, t] = score[i][t][0]                # Test loss\n",
        "      metrics['val_loss'][i,t] = history[i][t]['val_loss'][-1]    # Validation loss \n",
        "\n",
        "  metrics['av_val_acc'] = np.zeros(len(history[0]))\n",
        "  metrics['av_test_acc'] = np.zeros(len(history[0]))\n",
        "  metrics['av_val_loss'] = np.zeros(len(history[0]))\n",
        "  metrics['av_test_loss'] = np.zeros(len(history[0]))\n",
        "\n",
        "  # Calculate mean\n",
        "  metrics['av_val_acc'] = np.mean(metrics['val_acc'], axis = 0)\n",
        "  metrics['av_test_acc'] = np.mean(metrics['test_acc'], axis = 0)\n",
        "  metrics['av_val_loss'] = np.mean(metrics['val_loss'], axis = 0)\n",
        "  metrics['av_test_loss'] = np.mean(metrics['test_loss'], axis = 0)\n",
        "\n",
        "  return( metrics)\n",
        "\n",
        "# Brute force function to find best hyperparameters for lSTM-CNN \n",
        "\n",
        "def find_hyper_LSTM(x_train_curve, x_train_angle, x_test_curve, x_test_angle, ytrain, ytest, hyper):\n",
        "\n",
        "    # Change the y labels to 1D 1s or 0s.\n",
        "\n",
        "    ytr = np.zeros(len(ytrain))\n",
        "    yte = np.zeros(len(ytest))\n",
        "    for i in range (0,len(ytrain)):\n",
        "      if np.all(ytrain[i,:] == [1, 0]):\n",
        "        ytr[i] = 1\n",
        "    for i in range (0,len(ytest)):\n",
        "      if np.all(ytest[i,:] == [1, 0]):\n",
        "        yte[i] = 1\n",
        "\n",
        "    ytrain = ytr\n",
        "    ytest = yte\n",
        "\n",
        "    TIME_PERIODS = x_train_curve.shape[1]\n",
        "    num_features = 2\n",
        "    number_samples = x_train_curve.shape[0]\n",
        "    number_test = x_test_curve.shape[0]\n",
        "\n",
        "    # Create the correct input arrays for the LSTM network\n",
        "\n",
        "    x_train = np.zeros((number_samples, TIME_PERIODS, num_features))\n",
        "    x_test = np.zeros((number_test, TIME_PERIODS, num_features))\n",
        "\n",
        "    x_train[:,:,0] = x_train_angle\n",
        "    x_train[:,:,1] = x_train_curve\n",
        "    x_test[:,:,0] = x_test_angle\n",
        "    x_test[:,:,1] = x_test_curve\n",
        "\n",
        "    # First define the dictionaires which return the test accuracy and loss, \n",
        "    # train accuracy and loss, and validate accuracy and loss.\n",
        "    \n",
        "    all_score = {} \n",
        "    all_history = {}\n",
        "    \n",
        "    # Define some basic parameters\n",
        "    EPOCHS = 10\n",
        "    \n",
        "    # Now loop over the combinations of hyperparameters, each time creating a neural network, \n",
        "    # training it, and testing it. The test validation is then saved for each iteration.\n",
        "        \n",
        "    # MAIN LOOP\n",
        "    \n",
        "    for i in range (len(runs)):\n",
        "        print('Training network '+ str(i) )\n",
        "    # Build the CNN / LSTM \n",
        "        model_m = Sequential()\n",
        "    # Build a first convolutional layer\n",
        "        model_m.add(Conv1D(runs[i].Filter_number, runs[i].Filter_size_1, activation='relu', input_shape=(TIME_PERIODS,num_features)))\n",
        "    # Add a second convolutional layer\n",
        "        if runs[i].layers == 2 or runs[i].layers == 3:\n",
        "          model_m.add(MaxPooling1D(runs[i].Pooling_1))\n",
        "          model_m.add(Conv1D(runs[i].Filter_number, runs[i].Filter_size_2, activation='relu'))\n",
        "    # Add a third convolutional layer\n",
        "        if runs[i].layers == 3:\n",
        "          model_m.add(MaxPooling1D(runs[i].Pooling_2))\n",
        "          model_m.add(Conv1D(runs[i].Filter_number, runs[i].Filter_size_3, activation='relu'))\n",
        "    # Add an LSTM layer\n",
        "        model_m.add(MaxPooling1D(runs[i].Pooling_3))\n",
        "        model_m.add(LSTM(runs[i].LongShort))\n",
        "        model_m.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=1)]\n",
        "                                                          \n",
        "        model_m.compile(loss='binary_crossentropy',\n",
        "                            optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "        history = model_m.fit(x_train,ytrain,\n",
        "                              batch_size = runs[i].Batch_size,\n",
        "                              epochs=EPOCHS,\n",
        "                              callbacks=callbacks_list,\n",
        "                              validation_split=0.2,verbose=0)\n",
        "                              \n",
        "        score = model_m.evaluate(x_test, ytest, verbose=0)\n",
        "        \n",
        "        # Save the performance of the network in two dictionaries\n",
        "        \n",
        "        all_history[i] = history.history\n",
        "        all_score[i] = score\n",
        "           \n",
        "    return(all_history, all_score, model_m)\n",
        "\n",
        "# Brute force function to find best hyperparameters for 1D-CNN \n",
        "\n",
        "# Run a function/ loop that varies the hyperparameters and returns the accuracy and loss for each combinations of hyperparameters\n",
        "\n",
        "def find_hyper(xtrain, xtest, ytrain, ytest, hyper):\n",
        "    \n",
        "    # First define the dictionaires which return the test accuracy and loss, \n",
        "    # train accuracy and loss, and validate accuracy and loss.\n",
        "    \n",
        "    all_score = {} \n",
        "    all_history = {}\n",
        "    \n",
        "    # Define some basic parameters\n",
        "    \n",
        "    TIME_PERIODS = int(xtrain.shape[1]/2)\n",
        "    input_shape = xtrain.shape[1]\n",
        "    num_sensors = 2\n",
        "    num_classes = 2 \n",
        "    EPOCHS = 10\n",
        "    \n",
        "    # Now loop over the combinations of hyperparameters, each time creating a neural network, \n",
        "    # training it, and testing it. The test validation is then saved for each iteration.\n",
        "        \n",
        "    # MAIN LOOP\n",
        "    \n",
        "    for i in range (len(runs)):\n",
        "        print('Training network '+ str(i) )\n",
        "    # Build the CNN\n",
        "\n",
        "    # Add first layer\n",
        "        model_m = Sequential()\n",
        "        model_m.add(Reshape((TIME_PERIODS, num_sensors), input_shape=(input_shape,)))\n",
        "        model_m.add(Conv1D(runs[i].Filter_number, runs[i].Filter_size_1, activation='relu', input_shape=(TIME_PERIODS,num_sensors)))\n",
        "    # Add second layer    \n",
        "        if runs[i].layers == 2 or runs[i].layers == 3 or runs[i].layers == 4:\n",
        "          model_m.add(MaxPooling1D(runs[i].Pooling_1))\n",
        "          model_m.add(Conv1D(runs[i].Filter_number, runs[i].Filter_size_2, activation='relu'))\n",
        "    # Add third layer\n",
        "        if runs[i].layers == 3 or runs[i].layers == 4:\n",
        "          model_m.add(MaxPooling1D(runs[i].Pooling_2))\n",
        "          model_m.add(Conv1D(runs[i].Filter_number, runs[i].Filter_size_3, activation='relu'))\n",
        "    # Add fourth layer\n",
        "        if runs[i].layers == 4:\n",
        "          model_m.add(MaxPooling1D(runs[i].Pooling_3))\n",
        "          model_m.add(Conv1D(runs[i].Filter_number, runs[i].Filter_size_4, activation='relu'))\n",
        "    # Poolng, droput and output  \n",
        "        model_m.add(GlobalAveragePooling1D())\n",
        "        model_m.add(Dropout(0.5))\n",
        "        model_m.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # End of CNN\n",
        "        callbacks_list = [keras.callbacks.EarlyStopping(monitor='accuracy', patience=1)]\n",
        "    # Train CNN                                                     \n",
        "        model_m.compile(loss='binary_crossentropy',\n",
        "                            optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "        history = model_m.fit(xtrain,ytrain,\n",
        "                              batch_size = runs[i].Batch_size,\n",
        "                              epochs=EPOCHS,\n",
        "                              callbacks=callbacks_list,\n",
        "                              validation_split=0.2,verbose=0)\n",
        "    # Test CNN                         \n",
        "        score = model_m.evaluate(xtest, ytest, verbose=0)\n",
        "        \n",
        "    # Save the performance of the network in two dictionaries\n",
        "        all_history[i] = history.history\n",
        "        all_score[i] = score\n",
        "           \n",
        "    return(all_history, all_score, model_m)\n",
        "\n",
        "# Write function that predicts target labels with model and find out if those are correct or not. \n",
        "# Find out which trials are not correctly predicted.  \n",
        "\n",
        "def prediction(model, y_test, x_test, CNN):\n",
        "\n",
        "  # Find out the predictions of the model\n",
        "  y_pred_test = model.predict(x_test)\n",
        "\n",
        "  if CNN == 1:\n",
        "    y_pred_label = np.zeros((len(y_test),2))\n",
        "  # Change to 1s and 0s\n",
        "    for i in range (len(y_test)):\n",
        "      if y_pred_test[i,0] > y_pred_test[i,1]:\n",
        "        y_pred_label[i,:] = [1, 0]\n",
        "      else:\n",
        "        y_pred_label[i,:] = [0, 1]\n",
        "  elif CNN == 0:\n",
        "    y_pred_label = np.zeros((len(y_test),1))\n",
        "    yte = np.zeros(len(y_test))\n",
        "    for i in range (0,len(y_test)):\n",
        "      if np.all(ytest[i,:] == [1, 0]):\n",
        "        yte[i] = 1\n",
        "    y_test = yte\n",
        "    # Changes to 1s and 0s\n",
        "    for i in range (len(y_test)):\n",
        "      if y_pred_test[i] > 0.5:\n",
        "        y_pred_label[i] = 1\n",
        "\n",
        "  # Make empty list in which to store trial numbers which are misclassified and another for correctly classified trials\n",
        "  y_incorrect = []\n",
        "  y_correct = []\n",
        "\n",
        "  # Loop over all trials to check if they are classifed correctly\n",
        "  for i in range (len(y_test)):\n",
        "    if CNN == 1:\n",
        "      if np.all(y_pred_label[i,:] != y_test[i,:]):\n",
        "      # Store the 'incorrect' trials\n",
        "        y_incorrect = np.append(y_incorrect,i)\n",
        "      else:\n",
        "        y_correct = np.append(y_correct,i)\n",
        "    elif CNN == 0:\n",
        "      if y_pred_label[i] != y_test[i]:\n",
        "        y_incorrect = np.append(y_incorrect,i)\n",
        "      else:\n",
        "        y_correct = np.append(y_correct, i)\n",
        "\n",
        "  # Change float array to int array\n",
        "  y_incorrect = y_incorrect.astype(int)\n",
        "  y_correct = y_correct.astype(int)\n",
        "\n",
        "  # Calculate accuracy\n",
        "  acc = 1 - (len(y_incorrect)/len(y_test))\n",
        "\n",
        "  return(acc, y_correct, y_incorrect, y_pred_test, y_pred_label)\n",
        "\n",
        "  # Calculate the variance for correctly classified trials and the incorrectly classified trials. \n",
        "\n",
        "def variance(x_angle, x_curve, y):\n",
        "\n",
        "  prox = np.where(y == [1, 0])\n",
        "  dist = np.where(y == [0, 1])\n",
        "  prox = np.unique(prox[0])\n",
        "  dist = np.unique(dist[0])\n",
        "  var_prox_angle = np.var(x_angle[prox], axis=1)\n",
        "  var_prox_curve = np.var(x_curve[prox], axis=1)\n",
        "  var_dist_angle = np.var(x_angle[dist], axis=1)\n",
        "  var_dist_curve = np.var(x_curve[dist], axis=1)\n",
        "\n",
        "  return(var_prox_angle, var_prox_curve, var_dist_angle, var_dist_curve)\n",
        "\n",
        "def gradient(x_angle, x_curve, y):\n",
        "\n",
        "  # Return the gradient array for a whisking trace\n",
        "\n",
        "  prox = np.where(y == [1, 0])\n",
        "  dist = np.where(y == [0, 1])\n",
        "  prox = np.unique(prox[0])\n",
        "  dist = np.unique(dist[0])\n",
        "  grad = {}\n",
        "  grad['prox_angle'] = np.gradient(x_angle[prox], axis=1)\n",
        "  grad['prox_curve'] = np.gradient(x_curve[prox], axis=1)\n",
        "  grad['dist_angle'] = np.gradient(x_angle[dist], axis=1)\n",
        "  grad['dist_curve'] = np.gradient(x_curve[dist], axis=1)\n",
        "\n",
        "  return(grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbYylVIckt9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9de68007-3eaa-40db-fdfd-c96c76c54487"
      },
      "source": [
        "# Import all the data and preprocess\n",
        "whisk_data = import_data('an171923','/content/drive/My Drive/Processed data//')\n",
        "# Choose if you want data with no pole location and if you want correct trials\n",
        "no_zero , corr = 1 , 1\n",
        "xtrain, xtest, ytrain, ytest, x_t_c, x_t_a, x_test_c, x_test_a = pre_process(whisk_data, no_zero, corr)\n",
        "# Plot a number of the trials\n",
        "#number = 100\n",
        "#plot_some(x_t_c, x_t_a, ytrain, number)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are sigmas = 0, these are removed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHLmKjxo5q-J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3824d02b-cade-4ce1-e234-306cea82fef2"
      },
      "source": [
        "# Define a dictionary with all the hyperparameters you want to test in the lSTM_CNN\n",
        "\n",
        "hyper_lstm = { 'Batch_size': [32]\n",
        "              ,'Filter_number': [200]\n",
        "              ,'Filter_size_1': [10]\n",
        "              ,'Pooling_1': [3]\n",
        "              ,'Filter_size_2':[10]\n",
        "              ,'Pooling_2':[3]\n",
        "              ,'Filter_size_3':[10]\n",
        "              ,'Pooling_3':[ 3]\n",
        "              ,'layers': [2]\n",
        "              , 'LongShort': [100]\n",
        "              }\n",
        "runs = get_runs(hyper_lstm)\n",
        "print(len(runs))\n",
        "\n",
        "data = {'xtrain': xtrain, 'xtest': xtest, 'ytrain': ytrain, 'ytest': ytest, 'hyper': runs, 'x_train_curve': x_t_c, 'x_train_angle': x_t_a, 'x_test_curve': x_test_c, 'x_test_angle': x_test_a   }"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grduattYkt9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9edfc56-e17b-44ac-d45c-361dbec30ddd"
      },
      "source": [
        "# Define a dictionary with all the hyperparameters you want to test in the CNN.\n",
        "\n",
        "hyper = {'Batch_size': [32]\n",
        "         ,'Filter_number': [ 200]        \n",
        "         ,'Filter_size_1': [10]\n",
        "         ,'Pooling_1': [3]\n",
        "         ,'Filter_size_2': [ 10]\n",
        "         ,'Pooling_2': [3]\n",
        "         ,'Filter_size_3': [10]\n",
        "         #,'Pooling_3': [1]\n",
        "         #,'Filter_size_4': [10]\n",
        "         ,'layers': [  3]\n",
        "         }\n",
        "\n",
        "# This function makes combinations of all possible parameters\n",
        "runs = get_runs(hyper)\n",
        "\n",
        "print(len(runs))\n",
        "\n",
        "data = {'xtrain': xtrain, 'xtest': xtest, 'ytrain': ytrain, 'ytest': ytest, 'hyper': runs, 'x_train_curve': x_t_c, 'x_train_angle': x_t_a, 'x_test_curve': x_test_c, 'x_test_angle': x_test_a   }"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GxVd-TwLvWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "e2cbf5d6-b0a1-4a1a-9c6c-ca31a1a40cf2"
      },
      "source": [
        "# Build and train the network with all the hyperparameter combinations. Do this a number of times to get an average performance. \n",
        "number = 10\n",
        "LongShort = 0\n",
        "# Train CNN or LSTM, depending on the parameter above. \n",
        "history, score = find_average_metrics(find_hyper, find_hyper_LSTM, data, number, LongShort)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run of training: 0\n",
            "Training network 0\n",
            "Run of training: 1\n",
            "Training network 0\n",
            "Run of training: 2\n",
            "Training network 0\n",
            "Run of training: 3\n",
            "Training network 0\n",
            "Run of training: 4\n",
            "Training network 0\n",
            "Run of training: 5\n",
            "Training network 0\n",
            "Run of training: 6\n",
            "Training network 0\n",
            "Run of training: 7\n",
            "Training network 0\n",
            "Run of training: 8\n",
            "Training network 0\n",
            "Run of training: 9\n",
            "Training network 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ-N_capTzmv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ab09afb-913a-4a40-b72b-b3cd4b2bbef4"
      },
      "source": [
        "history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {0: {'accuracy': [0.5744540095329285,\n",
              "    0.7882197499275208,\n",
              "    0.8213104009628296,\n",
              "    0.8424884080886841,\n",
              "    0.8391793370246887],\n",
              "   'loss': [0.6762422919273376,\n",
              "    0.4801531434059143,\n",
              "    0.4260059595108032,\n",
              "    0.40662145614624023,\n",
              "    0.3948855996131897],\n",
              "   'val_accuracy': [0.7671957612037659,\n",
              "    0.8042327761650085,\n",
              "    0.8280423283576965,\n",
              "    0.8280423283576965,\n",
              "    0.8306878209114075],\n",
              "   'val_loss': [0.5582756400108337,\n",
              "    0.46900704503059387,\n",
              "    0.42218708992004395,\n",
              "    0.41024333238601685,\n",
              "    0.39135047793388367]}},\n",
              " 1: {0: {'accuracy': [0.5943083763122559,\n",
              "    0.7835870385169983,\n",
              "    0.8266049027442932,\n",
              "    0.834546685218811,\n",
              "    0.8491065502166748,\n",
              "    0.8557246923446655,\n",
              "    0.8550629019737244],\n",
              "   'loss': [0.6664260029792786,\n",
              "    0.48524051904678345,\n",
              "    0.4177573025226593,\n",
              "    0.39793649315834045,\n",
              "    0.38465359807014465,\n",
              "    0.3701045513153076,\n",
              "    0.3603319823741913],\n",
              "   'val_accuracy': [0.7698412537574768,\n",
              "    0.7962962985038757,\n",
              "    0.8253968358039856,\n",
              "    0.8042327761650085,\n",
              "    0.7883597612380981,\n",
              "    0.841269850730896,\n",
              "    0.8333333134651184],\n",
              "   'val_loss': [0.5367252230644226,\n",
              "    0.4526425004005432,\n",
              "    0.4310064911842346,\n",
              "    0.4464961886405945,\n",
              "    0.47685712575912476,\n",
              "    0.3893875181674957,\n",
              "    0.39068910479545593]}},\n",
              " 2: {0: {'accuracy': [0.6644605994224548,\n",
              "    0.8093977570533752,\n",
              "    0.816015899181366,\n",
              "    0.8213104009628296,\n",
              "    0.8378556966781616,\n",
              "    0.851753830909729,\n",
              "    0.8457974791526794],\n",
              "   'loss': [0.6108700633049011,\n",
              "    0.46184781193733215,\n",
              "    0.4427485466003418,\n",
              "    0.4391631782054901,\n",
              "    0.3902026414871216,\n",
              "    0.35952937602996826,\n",
              "    0.35642918944358826],\n",
              "   'val_accuracy': [0.7592592835426331,\n",
              "    0.7857142686843872,\n",
              "    0.7936508059501648,\n",
              "    0.8227513432502747,\n",
              "    0.8227513432502747,\n",
              "    0.8280423283576965,\n",
              "    0.8148148059844971],\n",
              "   'val_loss': [0.5145277976989746,\n",
              "    0.4613901376724243,\n",
              "    0.44782885909080505,\n",
              "    0.43198949098587036,\n",
              "    0.4100981652736664,\n",
              "    0.39050009846687317,\n",
              "    0.41050460934638977]}},\n",
              " 3: {0: {'accuracy': [0.6704169511795044,\n",
              "    0.8206485509872437,\n",
              "    0.8199867606163025],\n",
              "   'loss': [0.6087231636047363, 0.450158953666687, 0.41438066959381104],\n",
              "   'val_accuracy': [0.7989417910575867,\n",
              "    0.7910053133964539,\n",
              "    0.8227513432502747],\n",
              "   'val_loss': [0.4621143937110901, 0.4568040668964386, 0.4284138083457947]}},\n",
              " 4: {0: {'accuracy': [0.639973521232605,\n",
              "    0.8093977570533752,\n",
              "    0.8305757641792297,\n",
              "    0.8272666931152344],\n",
              "   'loss': [0.6403444409370422,\n",
              "    0.4576612412929535,\n",
              "    0.40773630142211914,\n",
              "    0.431092768907547],\n",
              "   'val_accuracy': [0.7962962985038757,\n",
              "    0.7777777910232544,\n",
              "    0.7936508059501648,\n",
              "    0.7936508059501648],\n",
              "   'val_loss': [0.4762428402900696,\n",
              "    0.47742292284965515,\n",
              "    0.4718661904335022,\n",
              "    0.4672877788543701]}},\n",
              " 5: {0: {'accuracy': [0.6075446605682373,\n",
              "    0.806750476360321,\n",
              "    0.8113831877708435,\n",
              "    0.8266049027442932,\n",
              "    0.8180013298988342],\n",
              "   'loss': [0.6482875347137451,\n",
              "    0.46541133522987366,\n",
              "    0.43996280431747437,\n",
              "    0.4034115672111511,\n",
              "    0.452389657497406],\n",
              "   'val_accuracy': [0.7089946866035461,\n",
              "    0.817460298538208,\n",
              "    0.8015872836112976,\n",
              "    0.7724867463111877,\n",
              "    0.820105791091919],\n",
              "   'val_loss': [0.5666787624359131,\n",
              "    0.4438728094100952,\n",
              "    0.45000240206718445,\n",
              "    0.5807132720947266,\n",
              "    0.43342018127441406]}},\n",
              " 6: {0: {'accuracy': [0.6426208019256592,\n",
              "    0.7981469035148621,\n",
              "    0.8180013298988342,\n",
              "    0.8226340413093567,\n",
              "    0.8385175466537476,\n",
              "    0.8444738388061523,\n",
              "    0.8504301905632019,\n",
              "    0.8338848352432251],\n",
              "   'loss': [0.6175393462181091,\n",
              "    0.47597262263298035,\n",
              "    0.44679924845695496,\n",
              "    0.4115310609340668,\n",
              "    0.4001827538013458,\n",
              "    0.3853358328342438,\n",
              "    0.3657023310661316,\n",
              "    0.4029112756252289],\n",
              "   'val_accuracy': [0.7830687761306763,\n",
              "    0.8015872836112976,\n",
              "    0.8095238208770752,\n",
              "    0.8121693134307861,\n",
              "    0.8253968358039856,\n",
              "    0.8280423283576965,\n",
              "    0.7962962985038757,\n",
              "    0.8306878209114075],\n",
              "   'val_loss': [0.48157089948654175,\n",
              "    0.46520623564720154,\n",
              "    0.44304290413856506,\n",
              "    0.43980953097343445,\n",
              "    0.4180697202682495,\n",
              "    0.40633970499038696,\n",
              "    0.4856514632701874,\n",
              "    0.40431416034698486]}},\n",
              " 7: {0: {'accuracy': [0.6492389440536499,\n",
              "    0.8021178245544434,\n",
              "    0.832561194896698,\n",
              "    0.8266049027442932],\n",
              "   'loss': [0.6260660290718079,\n",
              "    0.47016391158103943,\n",
              "    0.41450053453445435,\n",
              "    0.4177914261817932],\n",
              "   'val_accuracy': [0.7962962985038757,\n",
              "    0.820105791091919,\n",
              "    0.8280423283576965,\n",
              "    0.817460298538208],\n",
              "   'val_loss': [0.4708619713783264,\n",
              "    0.4511061906814575,\n",
              "    0.4261711835861206,\n",
              "    0.43064790964126587]}},\n",
              " 8: {0: {'accuracy': [0.6631370186805725,\n",
              "    0.8021178245544434,\n",
              "    0.8338848352432251,\n",
              "    0.8266049027442932],\n",
              "   'loss': [0.61592036485672,\n",
              "    0.4659280478954315,\n",
              "    0.41955235600471497,\n",
              "    0.4365697205066681],\n",
              "   'val_accuracy': [0.7354497313499451,\n",
              "    0.7724867463111877,\n",
              "    0.8121693134307861,\n",
              "    0.820105791091919],\n",
              "   'val_loss': [0.5283806324005127,\n",
              "    0.4928542375564575,\n",
              "    0.43419045209884644,\n",
              "    0.43229493498802185]}},\n",
              " 9: {0: {'accuracy': [0.6492389440536499,\n",
              "    0.7954996824264526,\n",
              "    0.8292521238327026,\n",
              "    0.8219721913337708],\n",
              "   'loss': [0.6402751207351685,\n",
              "    0.46828901767730713,\n",
              "    0.4066784977912903,\n",
              "    0.42009085416793823],\n",
              "   'val_accuracy': [0.7910053133964539,\n",
              "    0.8121693134307861,\n",
              "    0.7513227462768555,\n",
              "    0.8306878209114075],\n",
              "   'val_loss': [0.48669561743736267,\n",
              "    0.43658068776130676,\n",
              "    0.585481584072113,\n",
              "    0.428326815366745]}}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g-5ts8PRqIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "42affbfc-6111-4db0-e04f-ae6f128d58b5"
      },
      "source": [
        " # Plot the average test accuracy and test loss for each parameter combination\n",
        " \n",
        " metrics = get_average(history, score)\n",
        "fig = plt.figure(1)\n",
        "#plt.xticks(np.r_[0:len(metrics['av_test_acc']):1])\n",
        "plt.plot(metrics['test_acc'],'x--', label = 'test_acc')\n",
        "plt.plot(metrics['test_loss'],'x--', label = 'test_loss')\n",
        "plt.ylabel('Accuracy or loss')\n",
        "plt.legend(loc='right')\n",
        "plt.title('Testing averages')\n",
        "# fig.savefig('/content/drive/My Drive/Processed data/lstm_acc_5_times.png')\n",
        "for i in range (len(runs)):\n",
        "  print('par comb '+str(i))\n",
        "  print(runs[i])\n",
        "\n",
        "print(metrics['av_test_acc'])\n",
        "print(metrics['test_acc'])\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "par comb 0\n",
            "Run(Batch_size=32, Filter_number=200, Filter_size_1=10, Pooling_1=3, Filter_size_2=10, Pooling_2=3, Pooling_3=3, layers=2, LongShort=100)\n",
            "[0.83474576]\n",
            "[[0.83474576]]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IVBsYQM1p1N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "cc5f178f-996f-44e9-cadd-34c75d33976b"
      },
      "source": [
        "# Train the network with the best hyperparameters and save the model\n",
        "all_history, all_score, model_m = find_hyper_LSTM(x_t_c, x_t_a, x_test_c, x_test_a, ytrain, ytest, hyper_lstm)\n",
        "\n",
        "val_acc = round(all_score[0][1], 2)\n",
        "\n",
        "#model = load_model('my_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training network 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofT_xoZtbDr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the correct input arrays for the LSTM network\n",
        "\n",
        "TIME_PERIODS = x_t_c.shape[1]\n",
        "num_features = 2\n",
        "number_samples = x_t_c.shape[0]\n",
        "number_test = x_test_c.shape[0]\n",
        "\n",
        "x_train = np.zeros((number_samples, TIME_PERIODS, num_features))\n",
        "x_test = np.zeros((number_test, TIME_PERIODS, num_features))\n",
        "\n",
        "x_train[:,:,0] = x_t_a\n",
        "x_train[:,:,1] = x_t_c\n",
        "x_test[:,:,0] = x_test_a\n",
        "x_test[:,:,1] = x_test_c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7G50G8Jkt9e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "7149c305-5d11-4113-c377-3c9b760ea918"
      },
      "source": [
        "# Plots the test accuracy and test loss for all combinations\n",
        "\n",
        "scores = np.zeros((len(all_score),2))\n",
        "\n",
        "for i in range (len(all_score)):\n",
        "  scores[i,0] = all_score[i][1] # accuracy\n",
        "  scores[i,1] = all_score[i][0] # loss\n",
        "\n",
        "plt.xticks(np.r_[0:len(all_score):1])\n",
        "plt.plot(np.r_[0:len(all_score):1], scores[:,0],'x--', label = 'accuracy')\n",
        "plt.plot(np.r_[0:len(all_score):1], scores[:,1],'x--', label = 'loss')\n",
        "plt.ylabel('Accuracy or loss')\n",
        "plt.legend(loc='right')\n",
        "plt.title('Testing')\n",
        "\n",
        "# n = 3\n",
        "for n in range (0, len(all_score)):\n",
        "  print(n)\n",
        "  print(runs[n])\n",
        "  print(scores[n,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Run(Batch_size=32, layers=1, LongShort=100)\n",
            "[0.61448139 0.66012204]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEICAYAAABF82P+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}